{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from losses import LinearClassification\n",
    "from block_analysis import block_hessian, curvature_effects, eval_loss, update_params\n",
    "from lr_tools import lr_calibrate\n",
    "from models import conv_net\n",
    "from data import gen_cifar10_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation:\n",
    "\n",
    "- Different LR\n",
    "- More granular observations\n",
    "- GD vs SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim = 3\n",
    "hid_dim = 64\n",
    "out_dim = 10\n",
    "nlayer = 5\n",
    "bias = False \n",
    "use_bn = (False,False,False,False)\n",
    "mode = \"relu\"\n",
    "loss_mode = 'CrossEntropy'\n",
    "device = 0\n",
    "\n",
    "nsamp = 500\n",
    "\n",
    "save_model_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import zero_grad\n",
    "from activation_stats import first_order_analysis, plot_param, plot_activ\n",
    "from block_analysis import clone_model, eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Activation(nn.Module):\n",
    "    def __init__(self, mode=\"linear\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert mode in [\"relu\", \"linear\"]\n",
    "        self.mode = mode\n",
    "        self.last_msk = None\n",
    "        \n",
    "    def set_mode(self, mode):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert mode in [\"relu\", \"replay\", \"linear\"]\n",
    "        self.mode=mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.mode==\"relu\":\n",
    "            msk = (x>0).detach().to(x.dtype)\n",
    "            self.last_msk=msk\n",
    "            return x*msk\n",
    "        \n",
    "        elif self.mode==\"replay\":\n",
    "            assert self.mode==\"relu\" and self.last_msk is not None\n",
    "            return x*self.last_msk\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, inp, out, bias=False, mode=\"linear\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(inp, out, bias=bias)\n",
    "        self.act = Activation(mode)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.act(self.fc(x))\n",
    "    \n",
    "    def init_weights(self, init_type=\"variance\"):\n",
    "        if init_type==\"variance\":\n",
    "            var = {\"relu\":2, \"linear\":1}[self.act.mode]\n",
    "            with torch.no_grad():\n",
    "                self.fc.weight.normal_(std=math.sqrt(var/self.fc.weight.shape[0]))\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class var_center(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x - x.mean(dim=1, keepdim=True)\n",
    "\n",
    "class BN2d_ctrl(nn.Module):\n",
    "    def __init__(self, num_features, use_bn=(False, False, False, False), eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.ctr = use_bn[0]\n",
    "        self.std = use_bn[1]\n",
    "        self.scl = use_bn[2]\n",
    "        self.bias = use_bn[3]\n",
    "        self.mean = None\n",
    "        self.bn_std = None\n",
    "        self.eps = eps\n",
    "        if self.scl:\n",
    "            self.bn_weight = nn.Parameter(torch.ones(num_features))\n",
    "        if self.bias:\n",
    "            self.bn_bias = nn.Parameter(torch.zeros(num_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.ctr:\n",
    "            #self.mean = x.mean(dim=(0,2,3), keepdim=True)\n",
    "            x = x - x.mean(dim=(0,2,3), keepdim=True)#self.mean\n",
    "        if self.std:\n",
    "            #self.bn_std = torch.sqrt(x.var(dim=(0,2,3), keepdim=True) + self.eps)\n",
    "            x = x / x.std(dim=(0,2,3), keepdim=True)#self.bn_std\n",
    "        if self.scl:\n",
    "            x = torch.mul(x, self.bn_weight.unsqueeze(0).unsqueeze(-1).unsqueeze(-1))#[None,:,None,None]\n",
    "        if self.bias:\n",
    "            x = torch.add(x, self.bn_bias.unsqueeze(0).unsqueeze(-1).unsqueeze(-1))#[None,:,None,None]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x)\n",
    "\n",
    "class GAPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x,(2,3))\n",
    "\n",
    "class conv_bn(nn.Module):\n",
    "    def __init__(self, inp, out, stride=1, bias=False, use_bn=(False, False, False, False), mode=\"linear\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(inp, out, kernel_size=3, stride=stride, padding=1, bias=bias)\n",
    "        #self.var_c = var_center()\n",
    "        #self.bn = BN2d_ctrl(out, use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out)\n",
    "        with torch.no_grad():\n",
    "            self.bn.weight.fill_(1)\n",
    "        self.act = Activation(mode)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, a={\"relu\":0, \"linear\":1}[mode])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "class conv_net(nn.Module):\n",
    "    def __init__(self, inp, hid, out, nlayer, bias=False, use_bn=(False, False, False, False), mode=\"linear\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.l1 = conv_bn(inp, hid, stride=2, bias=bias, use_bn=use_bn, mode=mode)\n",
    "        self.layers = nn.Sequential(*[conv_bn(hid, hid, stride=2, bias=bias, use_bn=use_bn, mode=mode) \\\n",
    "                                      for i in range(max(0,nlayer-2))])\n",
    "        self.GAPool = GAPool()\n",
    "        self.out = FC(hid, out, bias=False, mode=\"linear\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.out(self.GAPool(self.layers(self.l1(x))))\n",
    "    \n",
    "    def get_mode(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return next(self._activations()).mode\n",
    "    \n",
    "    def set_mode(self, mode):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for activation in self._activations():\n",
    "            activation.set_mode(mode)\n",
    "    \n",
    "    def _activations(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return filter(lambda x:isinstance(x, Activation), self.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_model_ds_loss(loss_mode='CrossEntropy'):    \n",
    "    model =  conv_net(inp_dim, hid_dim, out_dim, nlayer, bias, use_bn, mode).cuda(device)\n",
    "    ds = gen_cifar10_ds(nsamp, device)\n",
    "    \n",
    "    assert loss_mode in [\"CrossEntropy\", \"Linear\"]\n",
    "    if loss_mode=='CrossEntropy':\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    elif loss_mode=='Linear':\n",
    "        loss_fn = LinearClassification(out_dim)\n",
    "        \n",
    "    return model, ds, loss_fn\n",
    "\n",
    "def correct(classifier, target):\n",
    "    return classifier.max(dim = 1)[1] == target\n",
    "\n",
    "def train_epoch(model, ds, loss_fn, lr):\n",
    "    zero_grad(model)\n",
    "    loss = eval_loss(model, ds, loss_fn)\n",
    "\n",
    "    grads = [x.grad for x in model.parameters()]\n",
    "    delta = grads#get_delta_params(model, grads)\n",
    "    params = list(model.parameters())\n",
    "    \n",
    "    update_params(params, delta, lr)\n",
    "\n",
    "    #delta_norm = list(map(lambda x: x.clone().norm().item(), delta))\n",
    "    model.zero_grad()\n",
    "    \n",
    "    acc = correct(model(ds[0][0]), ds[0][1])\n",
    "\n",
    "    return loss, acc.type(torch.FloatTensor).mean().item() #delta_norm, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def relative_error(a, b, eps=1e-6):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return abs((a - b) / min(abs(a), abs(b)))\n",
    "\n",
    "def init_dir(path, name=\"default\"):\n",
    "    path = f\"{save_model_dir}/{name}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def save_model(model, epoch, name=\"default\"):\n",
    "    torch.save(model.state_dict(), f\"{save_model_dir}/{name}/{epoch}.pth\".format(save_model_dir, epoch))\n",
    "\n",
    "def select(stats, column):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    stats = [stat[column]for stat in stats]\n",
    "    return pd.concat(stats, axis=1).T.set_index(np.arange(len(stats)))\n",
    "\n",
    "def plot_stats(stats, column, *args, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "    df = select(stats, column)\n",
    "    df.plot(*args, ax=ax, **kwargs)\n",
    "    \n",
    "def summarize_stats(stats):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2,2, figsize=(20, 20))\n",
    "    plot_stats(stats, 'a_l_std', ax=ax[0,0])\n",
    "    plot_stats(stats, 'a_l_m', ax=ax[0,1])\n",
    "    plot_stats(stats, 'W_g_std', ax=ax[1,0])\n",
    "    plot_stats(stats, 'W_std', ax=ax[1,1])\n",
    "    \n",
    "def run_analysis(model, ds, loss_fn, lr, epochs, valfreq=40):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    init_dir(save_model_dir)\n",
    "    val_stats, tr_stats = [],[]\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        if (epoch+1) % valfreq==0:\n",
    "            H = block_hessian(model, ds, loss_fn, lr)\n",
    "            delta, fo, ho, fostat = first_order_analysis(model, ds, loss_fn, lr)\n",
    "            error = relative_error(H.sum().item(), ho)\n",
    "            val_stats.append((H, delta, fo, ho, error, fostat))\n",
    "            save_model(model, epoch)\n",
    "\n",
    "        loss, acc = train_epoch(model, ds, loss_fn, lr)\n",
    "        tr_stats.append((loss, acc))\n",
    "\n",
    "    #H, delta, fo, ho, error, fostat = list(zip(*val_stats))\n",
    "    #loss, acc = list(zip(*tr_stats))\n",
    "    return val_stats, tr_stats\n",
    "    \n",
    "def unpack_stats(stats):\n",
    "    return list(zip(*stats))\n",
    "    \n",
    "def plot_acc_loss(acc, loss, ax=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "    ax[1].plot(loss)\n",
    "    ax[0].plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "lr = 0.01\n",
    "valfreq = 1\n",
    "\n",
    "model, ds, loss_fn = get_model_ds_loss(loss_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_stats, tr_stats = run_analysis(model, ds, loss_fn, lr, epochs, valfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, delta, fo, ho, error, fostat = unpack_stats(val_stats)\n",
    "loss, acc = unpack_stats(tr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(acc, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "ch = 20\n",
    "hw = 64\n",
    "\n",
    "bn1 = nn.BatchNorm2d(ch).cuda()\n",
    "with torch.no_grad():\n",
    "    bn1.weight.fill_(1)\n",
    "\n",
    "bn2 = BN2d_ctrl(ch, use_bn=(True,True,True,True)).cuda()\n",
    "x = torch.randn(bs, ch, hw, hw).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = bn1(x)\n",
    "o2 = bn2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(a,b):\n",
    "    m = (a-b).abs().max().item()\n",
    "    rel = (a-b).abs().sum() / a.abs().sum()\n",
    "    return m,rel\n",
    "\n",
    "diff(o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(o2):\n",
    "    print(o2.mean((0,2,3)), o2.std((0,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1.mean((0,2,3)), o1.std((0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_stats(fostat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "def vals2anime(vals):\n",
    "    fig, ax = plt.subplots()\n",
    "    xdata, ydata = range(len(vals)), vals\n",
    "    ln, = plt.plot([], [])\n",
    "    ln2, = plt.plot([], [], 'ro')\n",
    "\n",
    "    def init():\n",
    "        ax.set_xlim(0, len(vals))\n",
    "        ax.set_ylim(min(vals), max(vals))\n",
    "        ax.set_title(\"i=0\")\n",
    "        ln.set_data(xdata, ydata)\n",
    "        return ln, ln2\n",
    "\n",
    "    def update(i):\n",
    "        ln2.set_data(i, vals[i])\n",
    "        ax.set_title(f\"i={i}\")\n",
    "        return ln, ln2\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(vals),\n",
    "                        init_func=init, blit=True, interval=30)\n",
    "\n",
    "    ani = ani.to_jshtml()\n",
    "    #ani = ani.to_html5_video()\n",
    "    plt.close()\n",
    "    return HTML(ani)\n",
    "\n",
    "def normalize_imgs(imgs, time_norm=False):\n",
    "\n",
    "    if time_norm:\n",
    "        imgs = [img.abs() for img in imgs]\n",
    "        vmin = min([img.min() for img in imgs])\n",
    "        vmax = max([img.max() for img in imgs])\n",
    "\n",
    "    else:\n",
    "        imgs = [img.abs()/img.abs().max() for img in imgs]\n",
    "        vmin = 0\n",
    "        vmax = 1\n",
    "    \n",
    "    return imgs, vmin, vmax\n",
    "\n",
    "def imgs2anime(imgs, time_norm=False):\n",
    "    imgs, vmin, vmax = normalize_imgs(imgs, time_norm)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(imgs[0], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    def init():\n",
    "        im.set_data(imgs[0])\n",
    "        #ax.imshow(imgs[0])\n",
    "        ax.set_title(\"i=0\")\n",
    "\n",
    "    def update(i):\n",
    "        im.set_data(imgs[i])\n",
    "        #ax.imshow(imgs[i])\n",
    "        ax.set_title(f\"i={i}\")\n",
    "\n",
    "    ani = FuncAnimation(fig, update, init_func=init, frames=len(imgs),\n",
    "                        interval=30)\n",
    "    ani = ani.to_jshtml()\n",
    "    #ani = ani.to_html5_video()\n",
    "    plt.close()\n",
    "    return HTML(ani)\n",
    "\n",
    "def bars2anime(data):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    x = np.arange(1, data.shape[1]+1)\n",
    "    rectss = []\n",
    "    for i in range(data.shape[2]):\n",
    "        if i==0:\n",
    "            rectss.append(ax.bar(x, data[0,:,0]))\n",
    "        else:\n",
    "            rectss.append(ax.bar(x, data[0,:,i], bottom=data[0,:,:i].sum(axis=1)))\n",
    "\n",
    "    def set_rectss(rectss, d):\n",
    "        for i, rects in enumerate(rectss):\n",
    "            for j, rect in enumerate(rects):\n",
    "                rect.set_y(d[j,:i].sum())\n",
    "                rect.set_height(d[j,i])\n",
    "        \n",
    "        #return rectss\n",
    "    \n",
    "    def init():\n",
    "        set_rectss(rectss, data[0,:,:])\n",
    "        ax.set_title(\"i=0\")\n",
    "        return rectss[0]\n",
    "\n",
    "    def update(i):\n",
    "        set_rectss(rectss, data[i,:,:])\n",
    "        ax.set_title(f\"i={i}\")\n",
    "        return rectss[0]\n",
    "            \n",
    "    ani = FuncAnimation(fig, update, frames=data.shape[0],\n",
    "                        init_func=init, interval=50)\n",
    "\n",
    "    ani = ani.to_jshtml()\n",
    "    #ani = ani.to_html5_video()\n",
    "    plt.close()\n",
    "    return HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_data(H, data, loss, acc):    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "    # BH\n",
    "    H, vmin, vmax = normalize_imgs(H)\n",
    "    im = ax[0,0].imshow(H[0], vmin=vmin, vmax=vmax)\n",
    "    ax[0,0].set_title(\"BH\")\n",
    "\n",
    "    # layerwise delta_loss, fo, ho\n",
    "    ax[0,1].set_xlim(0, data.shape[1]+1)\n",
    "    margin = (data.max()-data.min())*1.08\n",
    "    ax[0,1].set_ylim(data.min()-margin, data.max()+margin)\n",
    "    width = 0.3\n",
    "    x = np.arange(1, data.shape[1]+1)\n",
    "    rectss = []\n",
    "    for i in range(data.shape[2]):\n",
    "        if i==0:\n",
    "            rectss.append(ax[0,1].bar(x, data[0,:,0], width=width))\n",
    "        else:\n",
    "            #rectss.append(ax[1].bar(x, data[0,:,i], bottom=data[0,:,:i].sum(axis=1)))\n",
    "            rectss.append(ax[0,1].bar(x+width*i, data[0,:,i], width=width))\n",
    "    ax[0,1].legend([\"delta\",\"fo\",\"ho\"])\n",
    "    ax[0,1].set_title(\"layerwise contrib\")\n",
    "    \n",
    "    # loss\n",
    "    ax[1,0].set_xlim(0, len(loss))\n",
    "    ax[1,0].set_ylim(min(loss), max(loss))\n",
    "    xdata = range(len(loss))\n",
    "    ln_l, = ax[1,0].plot([], [])\n",
    "    ln_l2, = ax[1,0].plot([], [], 'ro')\n",
    "    ax[1,0].set_title(\"loss\")\n",
    "\n",
    "    # acc\n",
    "    ax[1,1].set_xlim(0, len(acc))\n",
    "    ax[1,1].set_ylim(min(acc), max(acc))\n",
    "    ln_a, = ax[1,1].plot([], [])\n",
    "    ln_a2, = ax[1,1].plot([], [], 'ro')\n",
    "    ax[1,1].set_title(\"acc\")\n",
    "\n",
    "    def set_rectss(rectss, d):\n",
    "        for i, rects in enumerate(rectss):\n",
    "            for j, rect in enumerate(rects):\n",
    "                #rect.set_y(d[j,:i].sum())\n",
    "                rect.set_height(d[j,i])\n",
    "        \n",
    "    def init():\n",
    "        im.set_data(H[0])\n",
    "        \n",
    "        set_rectss(rectss, data[0,:,:])\n",
    "        \n",
    "        ln_l.set_data(xdata, loss)\n",
    "        ln_a.set_data(xdata, acc)\n",
    "        \n",
    "        fig.suptitle(\"i=0\")\n",
    "        return ln_l, ln_l2, ln_a, ln_a2\n",
    "\n",
    "    def update(i):\n",
    "        im.set_data(H[i])\n",
    "        \n",
    "        set_rectss(rectss, data[i,:,:])\n",
    "        margin = (data[i,:,:].max()-data[i,:,:].min())*0.1\n",
    "        ax[0,1].set_ylim(data[i,:,:].min()-margin, data[i,:,:].max()+margin)\n",
    "        \n",
    "        t = i*valfreq\n",
    "        ln_l2.set_data(t, loss[t])\n",
    "        ln_a2.set_data(t, acc[t])\n",
    "        \n",
    "        fig.suptitle(f\"i={i}\")\n",
    "        return ln_l, ln_l2, ln_a, ln_a2\n",
    "\n",
    "    ani = FuncAnimation(fig, update, init_func=init, frames=len(H), #frames=data.shape[0],\n",
    "                        interval=100, blit=True)\n",
    "    ani = ani.to_jshtml()\n",
    "    #ani = ani.to_html5_video()\n",
    "    plt.close()\n",
    "    return ani#HTML(ani)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BH = [h.cpu() for h in H]\n",
    "#BH = [h.cpu()[0:9:2,0:9:2] for h in H]\n",
    "BH = [h.cpu()[0:13:3,0:13:3] for h in H]\n",
    "\n",
    "lw_fo = [np.array(fo.W_g_sqr)*lr for fo in fostat]\n",
    "lw_ho = [h.numpy().sum(axis=0) for h in BH]\n",
    "lw_delta = [fo + ho for fo, ho in zip(lw_fo, lw_ho)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_fo_ho = np.array((lw_delta, lw_fo, lw_ho), dtype=np.float).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = visualize_data(BH, delta_fo_ho, loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stat_torchbn_init1.html\", \"w\") as f:\n",
    "    print(ani, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Tools (Refactored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class vals_anime():\n",
    "    def __init__(self, vals, ax, title):\n",
    "        self.ax = ax\n",
    "        self.vals = vals\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlim(0, len(vals))\n",
    "        ax.set_ylim(min(vals), max(vals))\n",
    "        ax.plot(range(len(vals)), vals)\n",
    "        self.ln, = ax.plot([], [], 'ro')\n",
    "        \n",
    "    def init(self):\n",
    "        return self.ln\n",
    "        \n",
    "    def update(self, i):\n",
    "        self.ln.set_data(i, self.vals[i])\n",
    "        return self.ln\n",
    "\n",
    "class imgs_anime():\n",
    "    def __init__(self, imgs, ax, title, time_norm=False):\n",
    "        self.ax = ax\n",
    "        self.imgs, vmin, vmax = self.normalize_imgs(imgs, time_norm)\n",
    "        self.im = ax.imshow(self.imgs[0], vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    def init(self):\n",
    "        return\n",
    "    \n",
    "    def update(self, i):\n",
    "        self.im.set_data(self.imgs[i])\n",
    "        return\n",
    "    \n",
    "    def normalize_imgs(self, imgs, time_norm=False):\n",
    "        if time_norm:\n",
    "            imgs = [img.abs() for img in imgs]\n",
    "            vmin = min([img.min() for img in imgs])\n",
    "            vmax = max([img.max() for img in imgs])\n",
    "        else:\n",
    "            imgs = [img.abs()/img.abs().max() for img in imgs]\n",
    "            vmin = 0\n",
    "            vmax = 1\n",
    "\n",
    "        return imgs, vmin, vmax\n",
    "    \n",
    "class bars_anime():\n",
    "    def __init__(self, data, ax, title):\n",
    "        self.ax = ax\n",
    "        ax.set_title(title)\n",
    "        self.data = data\n",
    "        ax.set_xlim(0, data.shape[1]+1)\n",
    "        ax.set_ylim(data.min(), data.max())\n",
    "        width = 0.1\n",
    "\n",
    "        x = np.arange(1, data.shape[1]+1)\n",
    "        self.rectss = []\n",
    "        for i in range(data.shape[2]):\n",
    "            if i==0:\n",
    "                self.rectss.append(ax.bar(x, data[0,:,0], width=width))\n",
    "            else:\n",
    "                self.rectss.append(ax.bar(x+width*i, data[0,:,i], width=width))\n",
    "\n",
    "    def init(self):\n",
    "        return\n",
    "        \n",
    "    def update(self, i):\n",
    "        self.set_rectss(self.rectss, self.data[i,:,:])\n",
    "        return\n",
    "        \n",
    "    def set_rectss(self, rectss, d):\n",
    "        for i, rects in enumerate(rectss):\n",
    "            for j, rect in enumerate(rects):\n",
    "                #rect.set_y(d[j,:i].sum())\n",
    "                rect.set_height(d[j,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def vis_data(H, data, loss, acc):    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12,10))\n",
    "    animes = []\n",
    "\n",
    "    animes.append(imgs_anime(H, ax[0,0], \"BH\"))\n",
    "    animes.append(bars_anime(data, ax[0,1], \"LW contrib\"))\n",
    "    ax[0,1].legend([\"delta\",\"fo\",\"ho\"])\n",
    "    animes.append(vals_anime(loss, ax[1,0], \"loss\"))\n",
    "    animes.append(vals_anime(acc, ax[1,1], \"acc\"))\n",
    "        \n",
    "    def init():\n",
    "        for anime in animes:\n",
    "            anime.init()\n",
    "        fig.suptitle(\"i=0\")\n",
    "        return\n",
    "\n",
    "    def update(i):\n",
    "        #t = i*valfreq\n",
    "        for anime in animes:\n",
    "            anime.update(i)        \n",
    "        fig.suptitle(f\"i={i}\")\n",
    "        return\n",
    "\n",
    "    ani = FuncAnimation(fig, update, init_func=init, frames=len(H),\n",
    "                        interval=100)\n",
    "    ani = ani.to_jshtml()\n",
    "    #ani = ani.to_html5_video()\n",
    "    plt.close()\n",
    "    return ani#HTML(ani)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vis_data(BH, delta_fo_ho, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
