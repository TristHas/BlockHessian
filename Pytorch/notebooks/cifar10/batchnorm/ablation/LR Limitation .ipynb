{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from helpers import get_model_ds_loss, init_dir, \\\n",
    "                    run_analysis, unpack_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim = 3\n",
    "hid_dim = 64\n",
    "out_dim = 10\n",
    "nlayer = 5\n",
    "bias = False \n",
    "use_bn = (False,False,False,False)\n",
    "bn_code = f\"{use_bn[0]:d}{use_bn[1]:d}{use_bn[2]:d}{use_bn[3]:d}\"\n",
    "mode = \"relu\"\n",
    "loss_mode = 'CrossEntropy'\n",
    "device = 0\n",
    "\n",
    "nsamp = 500\n",
    "\n",
    "save_model_dir = \"models\"\n",
    "datafolder = f\"./data/{bn_code}\"\n",
    "\n",
    "init_dir(datafolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "lr = 0.01\n",
    "valfreq = 1\n",
    "lrs = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.]\n",
    "\n",
    "for lr in lrs:\n",
    "    model, ds, loss_fn = get_model_ds_loss(inp_dim, hid_dim, out_dim,\n",
    "                                           nlayer, bias, use_bn, mode,\n",
    "                                           nsamp, device, loss_mode)\n",
    "\n",
    "    val_stats, tr_stats = run_analysis(model, ds, loss_fn, lr, epochs, valfreq)\n",
    "    #val_stats, tr_stats = run_analysis(model, ds, loss_fn, lr, epochs, valfreq, save_model_dir)\n",
    "    \n",
    "    H, delta, fo, ho, error, fostat = unpack_stats(val_stats)\n",
    "    loss, acc = unpack_stats(tr_stats)\n",
    "    \n",
    "    filename = f\"stat_lr{lr:.0e}_nl{nlayer}_hid_{hid_dim}_bn{bn_code}\"\n",
    "\n",
    "    stat = {\"H\": H,\n",
    "            \"delta\": delta,\n",
    "            \"fo\": fo,\n",
    "            \"ho\": ho,\n",
    "            \"error\": error,\n",
    "            \"fostat\": fostat,\n",
    "            \"loss\": loss,\n",
    "            \"acc\": acc,\n",
    "            \"lr\": lr}\n",
    "    \n",
    "    with open(f'{datafolder}/{filename}.pkl','wb') as f:\n",
    "        pickle.dump(stat,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = \"data/*\"\n",
    "out_dir = \"loss_acc_lr\"\n",
    "init_dir(out_dir)\n",
    "\n",
    "for dirname in sorted(glob.iglob(in_data)):\n",
    "    child_dir = os.path.join(out_dir, os.path.basename(dirname))\n",
    "    init_dir(child_dir)\n",
    "    for fname in sorted(glob.iglob(os.path.join(dirname, \"*\"))):\n",
    "        with open(fname,'rb') as f:\n",
    "            stat = pickle.load(f)\n",
    "        stat = {\"loss\": stat[\"loss\"],\n",
    "                \"acc\": stat[\"acc\"],\n",
    "                \"lr\": stat[\"lr\"]}\n",
    "        with open(f'{child_dir}/{os.path.basename(fname)}','wb') as f:\n",
    "            pickle.dump(stat,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
