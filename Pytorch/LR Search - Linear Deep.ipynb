{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MLP\n",
    "from data import gen_rnd_ds\n",
    "from losses import LinearClassification\n",
    "from block_analysis import block_hessian, curvature_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_ds_loss():    \n",
    "    model =  MLP(inp_dim, hid_dim, out_dim, nlayer, bias, mode).cuda(device)\n",
    "    ds = gen_rnd_ds(inp_dim, inp_mean, inp_var, \n",
    "                   out_dim, nsamp, device)\n",
    "    loss_fn = LinearClassification(out_dim)\n",
    "    return model, ds, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(lr, delta, h, H):\n",
    "    rel = abs((h.item() - H.sum().item()) / min(abs(H.sum().item()), abs(h.item())))\n",
    "    wari = h.item() / H.sum().item()\n",
    "    print(f\"LR {lr:.2E} \\t || Delta={delta:.2E}\\t ||Error={rel:.2E}  \\t|| hoe={h.item()} \\t|| H={H.sum().item()}\\t||wari={wari}\")\n",
    "\n",
    "def lr_range(model, ds, loss_fn, start=-8, stop=8, step=1, log_scale=False):\n",
    "    for lr in range(start, stop, step):\n",
    "        if log_scale:\n",
    "            lr = 10**lr\n",
    "        H = block_hessian(model, ds, loss_fn, lr)\n",
    "        delta, h = curvature_effects(model, ds, loss_fn, lr)\n",
    "        pp(lr, delta, h, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "mode = \"linear\"\n",
    "bias = False\n",
    "nlayer = 3\n",
    "inp_dim = 10 \n",
    "out_dim = 10\n",
    "hid_dim = 100\n",
    "\n",
    "# Data parameters\n",
    "nsamp = 100\n",
    "inp_mean = 0\n",
    "inp_var = 1\n",
    "\n",
    "# Others\n",
    "device = 0\n",
    "lr = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import pair_indexes, init_hessian, \\\n",
    "                  clone_model, get_param, \\\n",
    "                  get_delta_params, dot_product\n",
    "\n",
    "def update_params(params, deltas, lr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for param, delta in zip(params, deltas):\n",
    "        param.data.add_(-lr, delta)\n",
    "    \n",
    "def higher_orders(loss_t, loss_t1, lr, grad, delta):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    first_order = dot_product(grad, delta)\n",
    "    return (loss_t - loss_t1 - lr*first_order) / (2*lr**2)\n",
    "\n",
    "def eval_loss(model, ds, loss_fn, compute_grad=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for x,y in ds:\n",
    "        if compute_grad:\n",
    "            loss_ = loss_fn(model(x),y)\n",
    "            loss_.backward()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                loss_ = loss_fn(model(x),y)\n",
    "        loss+=loss_.item()\n",
    "    return loss\n",
    "\n",
    "def block_hessian_off_diag(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    base_model = clone_model(model)\n",
    "    H = init_hessian(base_model)\n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(base_model, ds, loss_fn, True)\n",
    "    grads = {i:x.grad for i,x in enumerate(base_model.parameters())}\n",
    "    \n",
    "    for i,j in pair_indexes(base_model):\n",
    "        # Copy the full model for now.\n",
    "        # If this is too slow, we should make update_params\n",
    "        # a context manager instead.\n",
    "        model = clone_model(base_model)\n",
    "        pair  = (get_param(model, i), get_param(model, j))\n",
    "        grad  = (grads[i].clone(), grads[j].clone())\n",
    "        # Compute delta_theta (=normalized gradient vector for now)\n",
    "        # But we need to consider other training algo (momentum, etc.)\n",
    "        delta = get_delta_params(model, grad) \n",
    "        # Possible context manager\n",
    "        update_params(pair, delta, lr) \n",
    "        loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "        \n",
    "        h = higher_orders(loss_t, loss_t1, lr, grad, delta)\n",
    "        H[i,j] = H[j,i] = h/2\n",
    "    return H\n",
    "\n",
    "def block_hessian_diag(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    base_model = clone_model(model) \n",
    "    diagonal = []\n",
    "    \n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(base_model, ds, loss_fn, True)\n",
    "    grads = {i:x.grad for i,x in enumerate(base_model.parameters())}\n",
    "\n",
    "    for i,_ in enumerate(base_model.parameters()):\n",
    "        model = clone_model(base_model)        \n",
    "        pair  = (get_param(model, i), )\n",
    "        grad  = (grads[i].clone(),)\n",
    "        delta = get_delta_params(model, grad)\n",
    "        \n",
    "        update_params(pair, delta, lr)\n",
    "        loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "        h = higher_orders(loss_t, loss_t1, lr, grad, delta)\n",
    "        diagonal.append(h)\n",
    "        \n",
    "    return torch.cat(list(map(lambda x:x.view((1,)), diagonal)))\n",
    "\n",
    "def _merge_blocks(H, d):\n",
    "    \"\"\"\n",
    "        Substract H_{ij} = H_{ij}-d_{i}-d_{j}\n",
    "        Set H_{ii} = d_{i}\n",
    "    \"\"\"\n",
    "    D = -(d.view(1,-1) + d.view(-1,1)) \n",
    "    D[range(D.shape[0]), range(D.shape[0])]=d\n",
    "    return H + D\n",
    "\n",
    "def block_hessian(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "        Missing merge_DH(D, H)\n",
    "    \"\"\"\n",
    "    d = block_hessian_diag(model, ds, loss_fn, lr)\n",
    "    H = block_hessian_off_diag(model, ds, loss_fn, lr)\n",
    "    return _merge_blocks(H, d)\n",
    "\n",
    "def curvature_effects(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    model = clone_model(model) \n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(model, ds, loss_fn, True)\n",
    "    grads = [x.grad for x in model.parameters()]\n",
    "    delta = get_delta_params(model, grads)\n",
    "    params = list(model.parameters())\n",
    "    \n",
    "    update_params(params, delta, lr)\n",
    "    loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "    return loss_t - loss_t1, higher_orders(loss_t, loss_t1, lr, grads, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = block_hessian(model, ds, loss_fn, lr)\n",
    "#h = curvature_effects(model, ds, loss_fn, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import pair_indexes, init_hessian, \\\n",
    "                  clone_model, get_param, \\\n",
    "                  get_delta_params, dot_product\n",
    "\n",
    "def update_params(params, deltas, lr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for param, delta in zip(params, deltas):\n",
    "        param.data.add_(-lr, delta)\n",
    "    \n",
    "def eval_loss(model, ds, loss_fn, compute_grad=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for x,y in ds:\n",
    "        if compute_grad:\n",
    "            loss_ = loss_fn(model(x),y)\n",
    "            loss_.backward()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                loss_ = loss_fn(model(x),y)\n",
    "        loss+=loss_.item()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_orders(loss_t, loss_t1, lr, grad, delta):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    first_order = dot_product(grad, delta)\n",
    "    return (loss_t - loss_t1 - lr*first_order) / (lr**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_hessian_off_diag(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    base_model = clone_model(model)\n",
    "    H = init_hessian(base_model)\n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(base_model, ds, loss_fn, True)\n",
    "    grads = {i:x.grad for i,x in enumerate(base_model.parameters())}\n",
    "    \n",
    "    for i,j in pair_indexes(base_model):\n",
    "        # Copy the full model for now.\n",
    "        # If this is too slow, we should make update_params\n",
    "        # a context manager instead.\n",
    "        model = clone_model(base_model)\n",
    "        pair  = (get_param(model, i), get_param(model, j))\n",
    "        grad  = (grads[i].clone(), grads[j].clone())\n",
    "        # Compute delta_theta (=normalized gradient vector for now)\n",
    "        # But we need to consider other training algo (momentum, etc.)\n",
    "        delta = grad#get_delta_params(model, grad) \n",
    "        # Possible context manager\n",
    "        update_params(pair, delta, lr) \n",
    "        loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "        \n",
    "        h = higher_orders(loss_t, loss_t1, lr, grad, delta)\n",
    "        H[i,j] = H[j,i] = h\n",
    "    return H\n",
    "\n",
    "def block_hessian_diag(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    base_model = clone_model(model) \n",
    "    diagonal = []\n",
    "    \n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(base_model, ds, loss_fn, True)\n",
    "    grads = {i:x.grad for i,x in enumerate(base_model.parameters())}\n",
    "\n",
    "    for i,_ in enumerate(base_model.parameters()):\n",
    "        model = clone_model(base_model)        \n",
    "        pair  = (get_param(model, i), )\n",
    "        grad  = (grads[i].clone(),)\n",
    "        delta = grad#get_delta_params(model, grad)\n",
    "        \n",
    "        update_params(pair, delta, lr)\n",
    "        loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "        h = higher_orders(loss_t, loss_t1, lr, grad, delta)\n",
    "        diagonal.append(h)\n",
    "        \n",
    "    return torch.cat(list(map(lambda x:x.view((1,)), diagonal)))\n",
    "\n",
    "def _merge_blocks(H, d):\n",
    "    \"\"\"\n",
    "        Substract H_{ij} = (H_{ij}-d_{i}-d_{j})/2\n",
    "        Set H_{ii} = d_{i}\n",
    "    \"\"\"\n",
    "    D = -(d.view(1,-1) + d.view(-1,1))\n",
    "    H = (H+D)/2\n",
    "    H[range(H.shape[0]), range(H.shape[0])]=d\n",
    "    return H \n",
    "\n",
    "def block_hessian(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "        Missing merge_DH(D, H)\n",
    "    \"\"\"\n",
    "    d = block_hessian_diag(model, ds, loss_fn, lr)\n",
    "    H = block_hessian_off_diag(model, ds, loss_fn, lr)\n",
    "    return _merge_blocks(H, d)\n",
    "\n",
    "def curvature_effects(model, ds, loss_fn, lr):\n",
    "    \"\"\"\n",
    "        Returns O(lr) terms of the Taylor expansion:\n",
    "        hoe = L(theta_t1) - L(theta_t) + lr * (delta_theta * grad_theta)\n",
    "    \"\"\"    \n",
    "    model = clone_model(model) \n",
    "    # Get loss(t) and gradients\n",
    "    loss_t = eval_loss(model, ds, loss_fn, True)\n",
    "    grads = [x.grad for x in model.parameters()]\n",
    "    delta = grads#get_delta_params(model, grads)\n",
    "    params = list(model.parameters())\n",
    "    \n",
    "    update_params(params, delta, lr)\n",
    "    loss_t1 = eval_loss(model, ds, loss_fn, False)\n",
    "    return loss_t - loss_t1, higher_orders(loss_t, loss_t1, lr, grads, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 1.00E-08 \t || Delta=0.00E+00\t ||Error=1.98E-07  \t|| hoe=-78765.53125 \t|| H=-78765.515625\t||wari=1.000000198373614\n",
      "LR 1.00E-07 \t || Delta=0.00E+00\t ||Error=6.20E-08  \t|| hoe=-7876.55224609375 \t|| H=-7876.5517578125\t||wari=1.0000000619917528\n",
      "LR 1.00E-06 \t || Delta=5.82E-11\t ||Error=1.77E+00  \t|| hoe=-729.4475708007812 \t|| H=-263.7862243652344\t||wari=2.7652981976450723\n",
      "LR 1.00E-05 \t || Delta=7.33E-09\t ||Error=7.51E-01  \t|| hoe=-5.423865795135498 \t|| H=-9.498395919799805\t||wari=0.5710296602639212\n",
      "LR 1.00E-04 \t || Delta=7.88E-08\t ||Error=2.76E+01  \t|| hoe=-0.0010558664798736572 \t|| H=0.02804858610033989\t||wari=-0.03764419625632617\n",
      "LR 1.00E-03 \t || Delta=7.88E-07\t ||Error=5.39E+00  \t|| hoe=1.0800249583553523e-05 \t|| H=-4.7371897380799055e-05\t||wari=-0.2279885371011362\n",
      "LR 1.00E-02 \t || Delta=7.88E-06\t ||Error=4.62E-01  \t|| hoe=-1.2460077414289117e-06 \t|| H=-1.8218315744888969e-06\t||wari=0.6839313572542902\n",
      "LR 1.00E-01 \t || Delta=7.87E-05\t ||Error=2.56E-02  \t|| hoe=-1.5854311641305685e-06 \t|| H=-1.6260855772998184e-06\t||wari=0.9749986017115051\n",
      "LR 1.00E+00 \t || Delta=7.86E-04\t ||Error=2.75E-04  \t|| hoe=-1.5594996511936188e-06 \t|| H=-1.559070369694382e-06\t||wari=1.0002753445306776\n",
      "LR 1.00E+01 \t || Delta=7.72E-03\t ||Error=2.16E-03  \t|| hoe=-1.5564635305054253e-06 \t|| H=-1.5598285472151474e-06\t||wari=0.9978427009072697\n",
      "LR 1.00E+02 \t || Delta=6.35E-02\t ||Error=2.20E-02  \t|| hoe=-1.526173150523391e-06 \t|| H=-1.5598244544889894e-06\t||wari=0.978426223624874\n",
      "LR 1.00E+03 \t || Delta=-4.36E-01\t ||Error=2.75E-01  \t|| hoe=-1.2233193729116465e-06 \t|| H=-1.5598236586811254e-06\t||wari=0.7842677382813884\n",
      "LR 1.00E+04 \t || Delta=1.88E+02\t ||Error=2.16E+00  \t|| hoe=1.8052180621452862e-06 \t|| H=-1.5598236586811254e-06\t||wari=-1.157321888341948\n",
      "LR 1.00E+05 \t || Delta=3.21E+05\t ||Error=2.16E+01  \t|| hoe=3.209058922948316e-05 \t|| H=-1.55982343130745e-06\t||wari=-20.573219112745797\n",
      "LR 1.00E+06 \t || Delta=3.35E+08\t ||Error=2.16E+02  \t|| hoe=0.0003349443431943655 \t|| H=-1.5598235449942877e-06\t||wari=-214.73220113214288\n",
      "LR 1.00E+07 \t || Delta=3.36E+11\t ||Error=2.16E+03  \t|| hoe=0.0033634810242801905 \t|| H=-1.55982343130745e-06\t||wari=-2156.3216430598864\n"
     ]
    }
   ],
   "source": [
    "model, ds, loss_fn = get_model_ds_loss()\n",
    "lr_range(model, ds, loss_fn, -8, 8, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0023, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_hessian_off_diag(model, ds, loss_fn, lr).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.8208e-09,  1.2688e-04,  2.1479e-04],\n",
       "         [ 1.2688e-04, -3.4925e-08,  8.1978e-04],\n",
       "         [ 2.1479e-04,  8.1978e-04,  0.0000e+00]], device='cuda:0'),\n",
       " tensor(0.0023, device='cuda:0'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = block_hessian(model, ds, loss_fn, 0.1)\n",
    "H, H.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6f31a69588>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAONElEQVR4nO3dfazeZX3H8ffHPkAYKA/dRlfKU9a4ObdMbAB1Mc3UDBtDl8gS/EPBaE50kumiyVATTEyWqX+4zGgkVYmwGCRTI8elxsDA4TQwKimU0iAHFsNJG1HKiviE1e/+OD+2e3fP6Tm97t+577v4fiV37t/Ddf+uL1eTT6/fE01VIUnH6wWTLkDSicnwkNTE8JDUxPCQ1MTwkNTE8JDUZKTwSHJmktuSPNJ9n7FEu18l2dN9ZkfpU9J0yCjPeST5GHCoqj6S5FrgjKr6u0XaPVNVp45Qp6QpM2p4PAxsq6qDSTYC36yqFy/SzvCQnmdGDY//rqrTB9afqqqjTl2SHAH2AEeAj1TVV5c43gwwA7CGNS8/hRc21/Z8l/XrJ13C1PvVqesmXcLU+8mh+R9V1W+3/Hbtcg2S3A6cvciuDx5HP+dW1YEkFwJ3JNlbVY8ON6qqncBOgBfmzLokrzmOLn6zrD3nvEmXMPWeumTjpEuYevfc/L7vt/522fCoqtcutS/JD5JsHDhteWKJYxzovh9L8k3gZcBR4SHpxDHqrdpZ4Kpu+Srg1uEGSc5IclK3vAF4FfDQiP1KmrBRw+MjwOuSPAK8rlsnydYkn+3a/CGwO8n9wJ0sXPMwPKQT3LKnLcdSVU8CR12YqKrdwNu75e8AfzxKP5Kmj0+YSmpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIatJLeCS5LMnDSeaSXLvI/pOS3NLtvyfJ+X30K2lyRg6PJGuATwGvB14CvCnJS4aavQ14qqp+H/hH4KOj9itpsvqYeVwMzFXVY1X1LPBFYMdQmx3Ajd3yl4DXJEkPfUuakD7CYxPw+MD6fLdt0TZVdQQ4DJzVQ9+SJmRtD8dYbAZRDW1IMgPMAJzMKaNXJmnV9DHzmAc2D6yfAxxYqk2StcCLgEPDB6qqnVW1taq2ruOkHkqTtFr6CI97gS1JLkiyHrgSmB1qMwtc1S1fAdxRVUfNPCSdOEY+bamqI0muAb4BrAFuqKp9ST4M7K6qWeBzwD8nmWNhxnHlqP1Kmqw+rnlQVbuAXUPbrhtY/jnwV330JWk6+ISppCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCa9hEeSy5I8nGQuybWL7L86yQ+T7Ok+b++jX0mTs3bUAyRZA3wKeB0wD9ybZLaqHhpqektVXTNqf5KmQx8zj4uBuap6rKqeBb4I7OjhuJKm2MgzD2AT8PjA+jxwySLt3pjk1cD3gL+tqseHGySZAWYATl57GmvPPa+H8p6fjvzX9yddwtT7zrdvnXQJU2/Nze2/7WPmkUW21dD614Dzq+pPgNuBGxc7UFXtrKqtVbV1/QtO6aE0Saulj/CYBzYPrJ8DHBhsUFVPVtUvutXPAC/voV9JE9RHeNwLbElyQZL1wJXA7GCDJBsHVi8H9vfQr6QJGvmaR1UdSXIN8A1gDXBDVe1L8mFgd1XNAn+T5HLgCHAIuHrUfiVNVh8XTKmqXcCuoW3XDSy/H3h/H31Jmg4+YSqpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIalJL+GR5IYkTyR5cIn9SfKJJHNJHkhyUR/9SpqcvmYenwcuO8b+1wNbus8M8Ome+pU0Ib2ER1XdBRw6RpMdwE214G7g9CQb++hb0mSM65rHJuDxgfX5btv/k2Qmye4ku5/99U/HVJqkFuMKjyyyrY7aULWzqrZW1db1LzhlDGVJajWu8JgHNg+snwMcGFPfklbBuMJjFnhLd9flUuBwVR0cU9+SVsHaPg6S5GZgG7AhyTzwIWAdQFVdD+wCtgNzwE+Bt/bRr6TJ6SU8qupNy+wv4F199CVpOviEqaQmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCa9hEeSG5I8keTBJfZvS3I4yZ7uc10f/UqanF7+oWvg88AngZuO0eZbVfWGnvqTNGG9zDyq6i7gUB/HknRi6GvmsRKvSHI/cAB4X1XtG26QZAaYAVh/yhk8dcnGMZZ3YvnOt2+ddAlT7y9+708nXcIJYK75l+MKj/uA86rqmSTbga8CW4YbVdVOYCfAqWdtrjHVJqnBWO62VNXTVfVMt7wLWJdkwzj6lrQ6xhIeSc5Okm754q7fJ8fRt6TV0ctpS5KbgW3AhiTzwIeAdQBVdT1wBfDOJEeAnwFXVpWnJdIJrJfwqKo3LbP/kyzcypX0POETppKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpqMHB5JNie5M8n+JPuSvHuRNknyiSRzSR5IctGo/UqarD7+oesjwHur6r4kpwHfTXJbVT000Ob1wJbucwnw6e5b0glq5JlHVR2sqvu65R8D+4FNQ812ADfVgruB05NsHLVvSZPT6zWPJOcDLwPuGdq1CXh8YH2eowNG0gmkt/BIcirwZeA9VfX08O5FflKLHGMmye4ku3/585/0VZqkVdBLeCRZx0JwfKGqvrJIk3lg88D6OcCB4UZVtbOqtlbV1nUn/1YfpUlaJX3cbQnwOWB/VX18iWazwFu6uy6XAoer6uCofUuanD7utrwKeDOwN8mebtsHgHMBqup6YBewHZgDfgq8tYd+JU3QyOFRVf/B4tc0BtsU8K5R+5I0PXzCVFITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1KTkcMjyeYkdybZn2Rfkncv0mZbksNJ9nSf60btV9Jkre3hGEeA91bVfUlOA76b5Laqemio3beq6g099CdpCow886iqg1V1X7f8Y2A/sGnU40qabqmq/g6WnA/cBby0qp4e2L4N+DIwDxwA3ldV+xb5/Qww062+FHiwt+L6sQH40aSLGGA9xzZt9cD01fTiqjqt5Ye9hUeSU4F/B/6+qr4ytO+FwK+r6pkk24F/qqotyxxvd1Vt7aW4nkxbTdZzbNNWD0xfTaPU08vdliTrWJhZfGE4OACq6umqeqZb3gWsS7Khj74lTUYfd1sCfA7YX1UfX6LN2V07klzc9fvkqH1Lmpw+7ra8CngzsDfJnm7bB4BzAarqeuAK4J1JjgA/A66s5c+XdvZQW9+mrSbrObZpqwemr6bmenq9YCrpN4dPmEpqYnhIajI14ZHkzCS3JXmk+z5jiXa/GnjMfXYV6rgsycNJ5pJcu8j+k5Lc0u2/p3u2ZVWtoKark/xwYFzevoq13JDkiSSLPoOTBZ/oan0gyUWrVctx1DS21yNW+LrGWMdo1V4hqaqp+AAfA67tlq8FPrpEu2dWsYY1wKPAhcB64H7gJUNt/hq4vlu+ErhllcdlJTVdDXxyTH9OrwYuAh5cYv924OtAgEuBe6agpm3Av45pfDYCF3XLpwHfW+TPa6xjtMKajnuMpmbmAewAbuyWbwT+cgI1XAzMVdVjVfUs8MWurkGDdX4JeM1zt6EnWNPYVNVdwKFjNNkB3FQL7gZOT7JxwjWNTa3sdY2xjtEKazpu0xQev1tVB2HhPxb4nSXanZxkd5K7k/QdMJuAxwfW5zl6kP+3TVUdAQ4DZ/Vcx/HWBPDGbgr8pSSbV7Ge5ay03nF7RZL7k3w9yR+No8PulPZlwD1DuyY2RseoCY5zjPp4zmPFktwOnL3Irg8ex2HOraoDSS4E7kiyt6oe7adCFptBDN/LXkmbPq2kv68BN1fVL5K8g4WZ0Z+vYk3HMu7xWYn7gPPq/16P+CpwzNcjRtW9rvFl4D018J7Xc7sX+cmqj9EyNR33GI115lFVr62qly7yuRX4wXNTt+77iSWOcaD7fgz4Jgsp2pd5YPBv7XNYeJFv0TZJ1gIvYnWnzMvWVFVPVtUvutXPAC9fxXqWs5IxHKsa8+sRy72uwQTGaDVeIZmm05ZZ4Kpu+Srg1uEGSc5IclK3vIGFp1uH/78ho7gX2JLkgiTrWbggOnxHZ7DOK4A7qrvitEqWrWnofPlyFs5pJ2UWeEt3R+FS4PBzp6OTMs7XI7p+jvm6BmMeo5XU1DRG47gCvcIrwmcB/wY80n2f2W3fCny2W34lsJeFOw57gbetQh3bWbga/SjwwW7bh4HLu+WTgX8B5oD/BC4cw9gsV9M/APu6cbkT+INVrOVm4CDwSxb+Bn0b8A7gHd3+AJ/qat0LbB3D+CxX0zUD43M38MpVrOXPWDgFeQDY0322T3KMVljTcY+Rj6dLajJNpy2STiCGh6QmhoekJoaHpCaGh6QmhoekJoaHpCb/A8g5BLWSDGuRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, ds, loss_fn = get_model_ds_loss()\n",
    "lr = 1\n",
    "H = block_hessian(model, ds, loss_fn, lr)\n",
    "plt.imshow(H.abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4256e-08,  4.3713e-08,  4.3713e-08],\n",
       "        [ 4.3713e-08, -4.5475e-08,  3.1150e-07],\n",
       "        [ 4.3713e-08,  3.1150e-07, -7.0941e-09]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 1.00E+00 \t || Error=6.54E-01  \t|| h=0.0019954312592744827 \t|| H=0.003301077987998724\n",
      "LR 2.00E+00 \t || Error=5.72E-01  \t|| h=0.0020995535887777805 \t|| H=0.003301077987998724\n",
      "LR 3.00E+00 \t || Error=4.97E-01  \t|| h=0.0022055571898818016 \t|| H=0.0033010789193212986\n",
      "LR 4.00E+00 \t || Error=4.27E-01  \t|| h=0.0023134429939091206 \t|| H=0.0033010775223374367\n",
      "LR 5.00E+00 \t || Error=3.62E-01  \t|| h=0.0024232110008597374 \t|| H=0.0033010777551680803\n",
      "LR 6.00E+00 \t || Error=3.02E-01  \t|| h=0.0025348614435642958 \t|| H=0.0033010784536600113\n",
      "LR 7.00E+00 \t || Error=2.46E-01  \t|| h=0.0026483931578695774 \t|| H=0.003301077289506793\n",
      "LR 8.00E+00 \t || Error=1.94E-01  \t|| h=0.0027638075407594442 \t|| H=0.003301076591014862\n",
      "LR 9.00E+00 \t || Error=1.46E-01  \t|| h=0.002881104126572609 \t|| H=0.0033010777551680803\n",
      "LR 1.00E+01 \t || Error=1.00E-01  \t|| h=0.0030002829153090715 \t|| H=0.0033010775223374367\n",
      "LR 1.10E+01 \t || Error=5.76E-02  \t|| h=0.003121343906968832 \t|| H=0.0033010770566761494\n",
      "LR 1.20E+01 \t || Error=1.75E-02  \t|| h=0.0032442871015518904 \t|| H=0.0033010777551680803\n",
      "LR 1.30E+01 \t || Error=2.06E-02  \t|| h=0.003369111567735672 \t|| H=0.0033010770566761494\n",
      "LR 1.40E+01 \t || Error=5.90E-02  \t|| h=0.0034958196338266134 \t|| H=0.0033010768238455057\n",
      "LR 1.50E+01 \t || Error=9.79E-02  \t|| h=0.0036244092043489218 \t|| H=0.0033010775223374367\n",
      "LR 1.60E+01 \t || Error=1.37E-01  \t|| h=0.003754880279302597 \t|| H=0.0033010777551680803\n",
      "LR 1.70E+01 \t || Error=1.78E-01  \t|| h=0.003887234488502145 \t|| H=0.0033010775223374367\n",
      "LR 1.80E+01 \t || Error=2.18E-01  \t|| h=0.004021470434963703 \t|| H=0.0033010775223374367\n",
      "LR 1.90E+01 \t || Error=2.59E-01  \t|| h=0.004157587420195341 \t|| H=0.0033010777551680803\n"
     ]
    }
   ],
   "source": [
    "lr_range(model, ds, loss_fn, 1, 20, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 637691.3125 1571090.625\n",
      "1e-07 -29363.134765625 -5872.3935546875\n",
      "1e-06 -258.7601318359375 -121.57786560058594\n",
      "1e-05 0.8995471000671387 1.8121325969696045\n",
      "0.0001 0.008458300493657589 0.006585310213267803\n",
      "0.001 0.00014551915228366852 0.00030877345125190914\n",
      "0.01 0.00042680767364799976 0.00042782630771398544\n",
      "0.1 0.00042814062908291817 0.00042815518099814653\n",
      "1 0.00042816251516342163 0.00042816437780857086\n",
      "10 0.00042816190398298204 0.00042816210770979524\n",
      "100 0.00042816175846382976 0.0004281617875676602\n",
      "1000 0.00042816175846382976 0.00042816175846382976\n",
      "10000 0.0004281617875676602 0.0004281617875676602\n",
      "100000 0.00042816181667149067 0.00042816181667149067\n",
      "1000000 0.0004281617875676602 0.0004281617875676602\n",
      "10000000 0.00042816175846382976 0.00042816175846382976\n"
     ]
    }
   ],
   "source": [
    "def func():\n",
    "    for log_lr in range(-8, 8): \n",
    "        lr = 10**log_lr\n",
    "        H = block_hessian(model, ds, loss_fn, lr)\n",
    "        h = curvature_effects(model, ds, loss_fn, lr)\n",
    "        print(lr, h.item(), H.sum().item())\n",
    "        \n",
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan nan\n",
      "1 0.039547525346279144 0.0537184402346611\n",
      "2 0.04295935854315758 0.05371849238872528\n",
      "3 0.04637118801474571 0.05371849983930588\n",
      "4 0.049783021211624146 0.05371849238872528\n",
      "5 0.05319485068321228 0.053718503564596176\n",
      "6 0.05660667642951012 0.053718507289886475\n",
      "7 0.06001850962638855 0.053718503564596176\n",
      "8 0.06343034654855728 0.05371851101517677\n",
      "9 0.06684217602014542 0.05371851474046707\n"
     ]
    }
   ],
   "source": [
    "for lr in range(10): \n",
    "    H = block_hessian(model, ds, loss_fn, lr)\n",
    "    h = curvature_effects(model, ds, loss_fn, lr)\n",
    "    print(lr, h.item(), H.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan nan\n",
      "1 0.0027682632207870483 0.005076628178358078\n",
      "2 0.00315653532743454 0.0050767287611961365\n",
      "3 0.003544833976775408 0.005076732020825148\n",
      "4 0.003933116793632507 0.005076744593679905\n",
      "5 0.004321407992392778 0.005076759494841099\n",
      "6 0.004709700588136911 0.005076758563518524\n",
      "7 0.005097983870655298 0.00507675064727664\n",
      "8 0.005486276000738144 0.0050767529755830765\n",
      "9 0.00587456626817584 0.005076766014099121\n"
     ]
    }
   ],
   "source": [
    "for lr in range(10): \n",
    "    H = block_hessian(model, ds, loss_fn, lr)\n",
    "    h = curvature_effects(model, ds, loss_fn, lr)\n",
    "    print(lr, h.item(), H.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
